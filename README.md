# Federated Learning for Financial Sentiment Analysis using FinBERT

This project applies **Federated Learning (FL)** to **financial sentiment analysis**
using the pretrained language model **FinBERT**.  
The goal is to evaluate how different FL optimization strategies perform when training
across multiple private financial text sources without sharing raw data.

We compare three algorithms:

âœ” **FedAvg** (baseline)  
âœ” **FedProx** (proximal stability term)  
âœ” **Adaptive Aggregation** (performance-weighted averaging)  

Training data is split across **three simulated clients**:

â€¢ Financial Twitter posts  
â€¢ Financial News headlines  
â€¢ Financial Reports / Statements  

to mimic privacy-preserving, real-world deployment.

---

## ğŸ¯ Objective

To study whether **FedProx or Adaptive Aggregation** improve stability,
neutral-class handling, and overall sentiment accuracy  
compared to standard **FedAvg**, when training on **non-IID financial datasets**.

---

## ğŸš€ Try the Models â€” Google Colab Demo

You can test the trained models directly in Colab  
without downloading anything:

ğŸ‘‰ **Federated FinBERT Demo Notebook**  
(loads FedAvg / FedProx / Adaptive and runs predictions)

> `Federated_FinBERT_Demo.ipynb`

Features:
âœ” model-selection menu  
âœ” simple `predict_sentiment("text")` function  
âœ” prints sentiment + class probabilities  

---

## ğŸ¤— HuggingFace Model Links

The trained models are publicly hosted:

ğŸ”¹ **FedAvg**  
https://huggingface.co/harshprasad03/FinBERT-FedAvg  

ğŸ”¹ **FedProx**  
https://huggingface.co/harshprasad03/FinBERT-FedProx  

ğŸ”¹ **Adaptive Aggregation**  
https://huggingface.co/harshprasad03/FinBERT-AdaptiveFedAvg  


Each model card contains:

â€¢ description  
â€¢ training setup  
â€¢ usage example  
â€¢ authorship credit  

---

## ğŸ“‚ Repository Structure

```

Project/
â”œâ”€â”€ 01_data_normalisation.ipynb
â”œâ”€â”€ 02_federated_setup.ipynb
â”œâ”€â”€ 03_local_finbert_twitter.ipynb
â”œâ”€â”€ 04_local_finbert_news.ipynb
â”œâ”€â”€ 05_local_finbert_reports.ipynb
â”œâ”€â”€ 06_federated_fedavg_finbert.ipynb
â”œâ”€â”€ 07_federated_fedavg_multiround.ipynb
â”œâ”€â”€ 08_federated_fedprox_multiround.ipynb
â”œâ”€â”€ 09_federated_adaptive_aggregation.ipynb
â”œâ”€â”€ 10_federated_results_comparison.ipynb
â”œâ”€â”€ Federated_FinBERT_Demo.ipynb
â”œâ”€â”€ data.zip
â”œâ”€â”€ results.zip

```

---

## ğŸ“Š Key Experimental Findings

| Method | Final Avg F1-Score |
|-------|--------------------|
| **FedAvg (10 rounds)** | ~0.835 |
| **FedProx (Î¼ = 0.05)** | **~0.855** |
| **Adaptive FedAvg** | ~0.823 |

### ğŸ§  Interpretation
âœ” **FedProx produced the most stable and balanced performance**,  
particularly for Neutral sentiment classification

âœ” **FedAvg showed mild optimistic bias**  
(tending to classify factual statements as Positive)

âœ” **Adaptive Aggregation converged smoothly but did not outperform FedProx or basic FedAvg**

These results support the idea that **FedProx reduces client drift**
in non-IID federated financial text settings.

---

## ğŸ— Model Architecture

Base model:
```

ProsusAI/finbert

```

Task:
```

3-class sentiment
(Positive / Neutral / Negative)

```

Federated setup:
```

3 clients
10 global rounds
3 local epochs

```

---

## ğŸ§ª Datasets

Three private client datasets:

â€¢ Financial Twitter posts  
â€¢ Financial News  
â€¢ Financial Reports  

Raw/processed/split data stored in:

```

data.zip

```

Validation splits used for global evaluation(present in data folder under splits).

---

## ğŸ›  Tech Stack

â€¢ Python  
â€¢ PyTorch  
â€¢ HuggingFace Transformers  
â€¢ Sklearn  
â€¢ Jupyter / Google Colab  

---

## ğŸ“Œ Project Status

This work forms part of a **Masterâ€™s-Level Research Project**
on **Federated NLP Applications in Finance**.

The project demonstrates:

âœ” privacy-preserving training  
âœ” domain-specific language modeling  
âœ” algorithm comparison  
âœ” reproducible experiments  

---

## ğŸ‘¥ Authors

**Harsh Prasad**  
**Sai Dhole**  

---

## ğŸ“œ License

This repository is released under the **MIT License**.

---

## ğŸ™ Acknowledgements

This project is built on:

`ProsusAI/finbert`  
and the HuggingFace ecosystem.

---
