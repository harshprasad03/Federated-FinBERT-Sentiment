{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4f7a6e-7874-4286-8df9-aefeb4ba1c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports \n",
    "import torch\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "#Checking Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4f319d-f276-4e6f-af0b-70a783f6850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Class Definition\n",
    "class FinSentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = labels.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3383ecee-f97a-437d-949c-6fbef92cf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Tokeniser\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1bebab-100e-4ca9-8766-129bd66d21dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation splits loaded\n"
     ]
    }
   ],
   "source": [
    "#Loading Validation Splits\n",
    "X_tw_val = pd.read_csv(\"data/splits/twitter_val_text.csv\").squeeze()\n",
    "y_tw_val = pd.read_csv(\"data/splits/twitter_val_labels.csv\").squeeze()\n",
    "\n",
    "X_news_val = pd.read_csv(\"data/splits/news_val_text.csv\").squeeze()\n",
    "y_news_val = pd.read_csv(\"data/splits/news_val_labels.csv\").squeeze()\n",
    "\n",
    "X_reports_val = pd.read_csv(\"data/splits/reports_val_text.csv\").squeeze()\n",
    "y_reports_val = pd.read_csv(\"data/splits/reports_val_labels.csv\").squeeze()\n",
    "\n",
    "print(\"Validation splits loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7743d940-af8a-4a9c-9663-668d709e4b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loaders ready\n"
     ]
    }
   ],
   "source": [
    "#DataLoaders\n",
    "tw_val_loader = DataLoader(\n",
    "    FinSentimentDataset(X_tw_val, y_tw_val, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "news_val_loader = DataLoader(\n",
    "    FinSentimentDataset(X_news_val, y_news_val, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "reports_val_loader = DataLoader(\n",
    "    FinSentimentDataset(X_reports_val, y_reports_val, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Validation loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0c320a-b7e0-4a62-abda-44debec00238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full datasets loaded\n"
     ]
    }
   ],
   "source": [
    "#Loading Full Processed Dataset\n",
    "twitter = pd.read_csv(\"data/processed/twitter.csv\")\n",
    "news = pd.read_csv(\"data/processed/news.csv\")\n",
    "reports = pd.read_csv(\"data/processed/reports.csv\")\n",
    "\n",
    "print(\"Full datasets loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc37050-e4ea-4f9f-914d-10a31767fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loaders ready\n"
     ]
    }
   ],
   "source": [
    "#Recreating Train Loaders\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tw_train, _, y_tw_train, _ = train_test_split(\n",
    "    twitter[\"text\"], twitter[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "X_news_train, _, y_news_train, _ = train_test_split(\n",
    "    news[\"text\"], news[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "X_reports_train, _, y_reports_train, _ = train_test_split(\n",
    "    reports[\"text\"], reports[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "tw_train_loader = DataLoader(\n",
    "    FinSentimentDataset(X_tw_train, y_tw_train, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "news_train_loader = DataLoader(\n",
    "    FinSentimentDataset(X_news_train, y_news_train, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "reports_train_loader = DataLoader(\n",
    "    FinSentimentDataset(X_reports_train, y_reports_train, tokenizer),\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da27540a-3b50-41cf-8d50-c2ae852ba9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Evaluation Function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(device)\n",
    "            )\n",
    "            pred = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            labels.extend(batch[\"labels\"].numpy())\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7466b13-dc7d-4b4a-9666-cd436013bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model initialised\n"
     ]
    }
   ],
   "source": [
    "#Initialising a Global Model\n",
    "global_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"ProsusAI/finbert\",\n",
    "    num_labels=3\n",
    ").to(device)\n",
    "\n",
    "print(\"Global model initialised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff8c26f-2ab2-42d1-a205-facb889b7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Train Function - FedAvg (Standard Fine Tuning)\n",
    "def local_train(model, train_loader, epochs=3):\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(device),\n",
    "                labels=batch[\"labels\"].to(device)\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16f2b14-bc48-46c6-bbc1-aee0d2c42134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive Aggregation Function\n",
    "def adaptive_fedavg(global_model, client_models, client_sizes, client_scores):\n",
    "\n",
    "    global_dict = global_model.state_dict()\n",
    "\n",
    "    # Weighted score = size Ã— performance\n",
    "    weighted_scores = [\n",
    "        client_sizes[i] * client_scores[i]\n",
    "        for i in range(len(client_models))\n",
    "    ]\n",
    "\n",
    "    total_weight = sum(weighted_scores)\n",
    "\n",
    "    for key in global_dict.keys():\n",
    "        global_dict[key] = sum(\n",
    "            weighted_scores[i] * client_models[i].state_dict()[key]\n",
    "            for i in range(len(client_models))\n",
    "        ) / total_weight\n",
    "\n",
    "    global_model.load_state_dict(global_dict)\n",
    "\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d43a79-2510-4666-825b-df91eeabf75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Adaptive Round 1/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.4737 | News F1: 0.5751 | Reports F1: 0.6085\n",
      "Average F1: 0.5524\n",
      "\n",
      "===== Adaptive Round 2/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.5963 | News F1: 0.8725 | Reports F1: 0.8020\n",
      "Average F1: 0.7570\n",
      "\n",
      "===== Adaptive Round 3/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6218 | News F1: 0.9210 | Reports F1: 0.8355\n",
      "Average F1: 0.7928\n",
      "\n",
      "===== Adaptive Round 4/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6312 | News F1: 0.9240 | Reports F1: 0.8322\n",
      "Average F1: 0.7958\n",
      "\n",
      "===== Adaptive Round 5/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6351 | News F1: 0.9283 | Reports F1: 0.8349\n",
      "Average F1: 0.7994\n",
      "\n",
      "===== Adaptive Round 6/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6282 | News F1: 0.9718 | Reports F1: 0.8591\n",
      "Average F1: 0.8197\n",
      "\n",
      "===== Adaptive Round 7/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6275 | News F1: 0.9741 | Reports F1: 0.8630\n",
      "Average F1: 0.8215\n",
      "\n",
      "===== Adaptive Round 8/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6306 | News F1: 0.9604 | Reports F1: 0.8586\n",
      "Average F1: 0.8165\n",
      "\n",
      "===== Adaptive Round 9/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6306 | News F1: 0.9649 | Reports F1: 0.8578\n",
      "Average F1: 0.8178\n",
      "\n",
      "===== Adaptive Round 10/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter F1: 0.6310 | News F1: 0.9752 | Reports F1: 0.8637\n",
      "Average F1: 0.8233\n"
     ]
    }
   ],
   "source": [
    "#Adaptive Federated Training (Multi Round)\n",
    "ROUNDS = 10\n",
    "LOCAL_EPOCHS = 3\n",
    "\n",
    "adaptive_results = []\n",
    "\n",
    "for r in range(ROUNDS):\n",
    "    print(f\"\\n===== Adaptive Round {r+1}/{ROUNDS} =====\")\n",
    "\n",
    "    #Copying global model to clients\n",
    "    tw_model = copy.deepcopy(global_model)\n",
    "    news_model = copy.deepcopy(global_model)\n",
    "    reports_model = copy.deepcopy(global_model)\n",
    "\n",
    "    #Local training\n",
    "    tw_model = local_train(tw_model, tw_train_loader, LOCAL_EPOCHS)\n",
    "    news_model = local_train(news_model, news_train_loader, LOCAL_EPOCHS)\n",
    "    reports_model = local_train(reports_model, reports_train_loader, LOCAL_EPOCHS)\n",
    "\n",
    "    #Evaluating each client model on its validation set\n",
    "    _, tw_f1 = evaluate_model(tw_model, tw_val_loader)\n",
    "    _, news_f1 = evaluate_model(news_model, news_val_loader)\n",
    "    _, reports_f1 = evaluate_model(reports_model, reports_val_loader)\n",
    "\n",
    "    client_scores = [tw_f1, news_f1, reports_f1]\n",
    "    client_sizes = [len(X_tw_train), len(X_news_train), len(X_reports_train)]\n",
    "\n",
    "    #Adaptive Aggregation \n",
    "    global_model = adaptive_fedavg(\n",
    "        global_model,\n",
    "        [tw_model, news_model, reports_model],\n",
    "        client_sizes,\n",
    "        client_scores\n",
    "    )\n",
    "\n",
    "    #Evaluating updated global model\n",
    "    _, g_tw = evaluate_model(global_model, tw_val_loader)\n",
    "    _, g_news = evaluate_model(global_model, news_val_loader)\n",
    "    _, g_reports = evaluate_model(global_model, reports_val_loader)\n",
    "\n",
    "    avg_f1 = (g_tw + g_news + g_reports) / 3\n",
    "\n",
    "    adaptive_results.append([r+1, g_tw, g_news, g_reports, avg_f1])\n",
    "\n",
    "    print(f\"Twitter F1: {g_tw:.4f} | News F1: {g_news:.4f} | Reports F1: {g_reports:.4f}\")\n",
    "    print(f\"Average F1: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79cfc97b-e246-45af-8568-cb55c90768d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Twitter_F1</th>\n",
       "      <th>News_F1</th>\n",
       "      <th>Reports_F1</th>\n",
       "      <th>Avg_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.971818</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.819682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.627504</td>\n",
       "      <td>0.974073</td>\n",
       "      <td>0.862977</td>\n",
       "      <td>0.821518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.960372</td>\n",
       "      <td>0.858615</td>\n",
       "      <td>0.816534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.630588</td>\n",
       "      <td>0.964942</td>\n",
       "      <td>0.857829</td>\n",
       "      <td>0.817786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.630984</td>\n",
       "      <td>0.975198</td>\n",
       "      <td>0.863701</td>\n",
       "      <td>0.823294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round  Twitter_F1   News_F1  Reports_F1    Avg_F1\n",
       "5      6    0.628150  0.971818    0.859079  0.819682\n",
       "6      7    0.627504  0.974073    0.862977  0.821518\n",
       "7      8    0.630613  0.960372    0.858615  0.816534\n",
       "8      9    0.630588  0.964942    0.857829  0.817786\n",
       "9     10    0.630984  0.975198    0.863701  0.823294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving Adaptive Aggregation Results\n",
    "\n",
    "import os\n",
    "os.makedirs(\"results/adaptive\", exist_ok=True)\n",
    "\n",
    "adaptive_df = pd.DataFrame(\n",
    "    adaptive_results,\n",
    "    columns=[\"Round\",\"Twitter_F1\",\"News_F1\",\"Reports_F1\",\"Avg_F1\"]\n",
    ")\n",
    "\n",
    "adaptive_df.to_csv(\"results/adaptive/adaptive_fedavg_10_rounds.csv\", index=False)\n",
    "\n",
    "print(\"Results saved successfully\")\n",
    "adaptive_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3b47b7-0925-4361-8efa-0add92905449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive FedAvg model saved\n"
     ]
    }
   ],
   "source": [
    "#Saving Final Adaptive Global Model\n",
    "os.makedirs(\"models/adaptive_fedavg\", exist_ok=True)\n",
    "\n",
    "global_model.save_pretrained(\"models/adaptive_fedavg\")\n",
    "tokenizer.save_pretrained(\"models/adaptive_fedavg\")\n",
    "\n",
    "print(\"Adaptive FedAvg model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "862a8f43-312b-4961-ba4d-fa6866ac8a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Twitter_F1</th>\n",
       "      <th>News_F1</th>\n",
       "      <th>Reports_F1</th>\n",
       "      <th>Avg_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.473695</td>\n",
       "      <td>0.575124</td>\n",
       "      <td>0.608521</td>\n",
       "      <td>0.552446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.596299</td>\n",
       "      <td>0.872550</td>\n",
       "      <td>0.802010</td>\n",
       "      <td>0.756953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.621846</td>\n",
       "      <td>0.921038</td>\n",
       "      <td>0.835530</td>\n",
       "      <td>0.792805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.631242</td>\n",
       "      <td>0.924029</td>\n",
       "      <td>0.832222</td>\n",
       "      <td>0.795831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.635147</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.834875</td>\n",
       "      <td>0.799439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.971818</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.819682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.627504</td>\n",
       "      <td>0.974073</td>\n",
       "      <td>0.862977</td>\n",
       "      <td>0.821518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.960372</td>\n",
       "      <td>0.858615</td>\n",
       "      <td>0.816534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.630588</td>\n",
       "      <td>0.964942</td>\n",
       "      <td>0.857829</td>\n",
       "      <td>0.817786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.630984</td>\n",
       "      <td>0.975198</td>\n",
       "      <td>0.863701</td>\n",
       "      <td>0.823294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round  Twitter_F1   News_F1  Reports_F1    Avg_F1\n",
       "0      1    0.473695  0.575124    0.608521  0.552446\n",
       "1      2    0.596299  0.872550    0.802010  0.756953\n",
       "2      3    0.621846  0.921038    0.835530  0.792805\n",
       "3      4    0.631242  0.924029    0.832222  0.795831\n",
       "4      5    0.635147  0.928296    0.834875  0.799439\n",
       "5      6    0.628150  0.971818    0.859079  0.819682\n",
       "6      7    0.627504  0.974073    0.862977  0.821518\n",
       "7      8    0.630613  0.960372    0.858615  0.816534\n",
       "8      9    0.630588  0.964942    0.857829  0.817786\n",
       "9     10    0.630984  0.975198    0.863701  0.823294"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cf2c7-7201-4a2d-ace2-69c0327437e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
